{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import os\n",
    "\n",
    "# Importing  both time traveled to work csvs and concatonating into a sigle dataframe\n",
    "time_traveled_dir = ['Travel Time to Work', 'Travel Time County and State Level']\n",
    "for dir in time_traveled_dir:\n",
    "\n",
    "    path = f'Resources/{dir}'\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    travel_df = pd.DataFrame()\n",
    "    cs_travel_df = pd.DataFrame()\n",
    "\n",
    "    for file in files:\n",
    "        if dir == 'Travel Time to Work':\n",
    "            temp = pd.read_csv(path + '\\\\' + file, skiprows=[1])\n",
    "            temp = temp[['B08303_001E', 'B08303_002E', 'B08303_003E', 'B08303_004E', 'B08303_005E', 'B08303_006E', 'B08303_007E', \\\n",
    "                'B08303_008E', 'B08303_009E', 'B08303_010E', 'B08303_011E', 'B08303_012E', 'B08303_013E', 'NAME']]\n",
    "            # Renaming columns \n",
    "            temp.columns = ['Total Estimate', 'Estimate Less than 5 min', 'Estimate 5 to 9 min', 'Estimate 10 to 14 min', \\\n",
    "                'Estimate 15 to 19 min', 'Estimate 20 to 24 min', 'Estimate 25 to 29 min', 'Estimate 30 to 34 min', 'Estimate 35 to 39 min', \\\n",
    "                'Estimate 40 to 44 min', 'Estimate 45 to 59 min', 'Estimate 60 to 89 min', 'Estimate 90 or more min', 'State']\n",
    "            # Adding a column for respective years\n",
    "            temp['Year'] = file.split(' ')[0]\n",
    "            # Reordering columns\n",
    "            temp = temp[['Year', 'State', 'Total Estimate', 'Estimate Less than 5 min', 'Estimate 5 to 9 min', 'Estimate 10 to 14 min', \\\n",
    "                'Estimate 15 to 19 min', 'Estimate 20 to 24 min', 'Estimate 25 to 29 min', 'Estimate 30 to 34 min', 'Estimate 35 to 39 min', \\\n",
    "                'Estimate 40 to 44 min', 'Estimate 45 to 59 min', 'Estimate 60 to 89 min', 'Estimate 90 or more min']]\n",
    "            # Removing Puerto Rico\n",
    "            temp = temp[temp['State'].str.contains('Puerto Rico')==False]\n",
    "            # Appending each new temporary dataframe into one\n",
    "            travel_df = travel_df.append(temp)\n",
    "        elif dir == 'Travel Time County and State Level':\n",
    "            temp = pd.read_csv(path + '\\\\' + file, skiprows=[1])\n",
    "            temp = temp[['B08131_001E', 'B08131_002E', 'B08131_003E', 'B08131_004E', 'B08131_005E', 'NAME']]\n",
    "            # Renaming columns \n",
    "            temp.columns = ['Estiamte Aggregate Travel Time (min)', 'Worked in State of Residence Estimate Aggregate (min)', \\\n",
    "                'Worked in County of Residence Estimate Aggregate (min)', 'Worked Outside County of Residence Estimate Aggregate (min)', \\\n",
    "                'Worked Outside State of Residence Estimate Aggregate (min)', 'State']\n",
    "            # Adding a column for respective years\n",
    "            temp['Year'] = file.split(' ')[0]\n",
    "            # Reordering columns\n",
    "            temp = temp[['Year', 'State', 'Estiamte Aggregate Travel Time (min)', 'Worked in State of Residence Estimate Aggregate (min)', \\\n",
    "                'Worked in County of Residence Estimate Aggregate (min)', 'Worked Outside County of Residence Estimate Aggregate (min)', \\\n",
    "                'Worked Outside State of Residence Estimate Aggregate (min)']]\n",
    "                # Removing Puerto Rico\n",
    "            temp = temp[temp['State'].str.contains('Puerto Rico')==False]\n",
    "            # Appending each new temporary dataframe into one\n",
    "            cs_travel_df = cs_travel_df.append(temp)\n",
    "\n",
    "# Importing HPI csv and making into a dataframe\n",
    "hpi_quarterly = pd.read_csv('Resources/HPI/HPI Quarterly State Level.csv')\n",
    "# Removing Warning column\n",
    "hpi_quarterly = hpi_quarterly[['state', 'yr', 'qtr', 'index_nsa', 'index_sa']]\n",
    "# Renaming columns\n",
    "hpi_quarterly.columns = ['State', 'Year', 'Quarter', 'NSA Index', 'SA Index']\n",
    "# Gropuby to get mean of SA and NSA index for each state and year\n",
    "hpi_yearly = hpi_quarterly.groupby(['State', 'Year'], as_index=False).agg({'NSA Index': 'mean', 'SA Index': 'mean'})\n",
    "# Renaming columns again \n",
    "hpi_yearly.columns = ['State', 'Year', 'Yearly Average Index (NSA)', 'Yearly Average Index (SA)']\n",
    "# Only keeping years 2010-2019\n",
    "hpi_yearly = hpi_yearly.loc[(hpi_yearly['Year'].astype(int) >= 2010) & (hpi_yearly['Year'].astype(int) <= 2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_to_abbrev = {\"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\", \"Colorado\": \"CO\", \\\n",
    "    \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \\\n",
    "    \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\", \\\n",
    "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\",\n",
    "\"Mississippi\": \"MS\",\n",
    "\"Missouri\": \"MO\",\n",
    "\"Montana\": \"MT\",\n",
    "\"Nebraska\": \"NE\",\n",
    "\"Nevada\": \"NV\",\n",
    "\"New Hampshire\": \"NH\",\n",
    "\"New Jersey\": \"NJ\",\n",
    "\"New Mexico\": \"NM\",\n",
    "\"New York\": \"NY\",\n",
    "\"North Carolina\": \"NC\",\n",
    "\"North Dakota\": \"ND\",\n",
    "\"Ohio\": \"OH\",\n",
    "\"Oklahoma\": \"OK\",\n",
    "\"Oregon\": \"OR\",\n",
    "\"Pennsylvania\": \"PA\",\n",
    "\"Rhode Island\": \"RI\",\n",
    "\"South Carolina\": \"SC\",\n",
    "\"South Dakota\": \"SD\",\n",
    "\"Tennessee\": \"TN\",\n",
    "\"Texas\": \"TX\",\n",
    "\"Utah\": \"UT\",\n",
    "\"Vermont\": \"VT\",\n",
    "\"Virginia\": \"VA\",\n",
    "\"Washington\": \"WA\",\n",
    "\"West Virginia\": \"WV\",\n",
    "\"Wisconsin\": \"WI\",\n",
    "\"Wyoming\": \"WY\",\n",
    "\"District of Columbia\": \"DC\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-006aa71647d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Merging HPI and travel time dataframes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtravel_hpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtravel_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcs_travel_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhpi_yearly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 74\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[0mcross_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_validate_specification\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m                 \u001b[0mcommon_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft_cols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon_cols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m                     raise MergeError(\n\u001b[0m\u001b[0;32m   1284\u001b[0m                         \u001b[1;34m\"No common columns to perform merge on. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m                         \u001b[1;34mf\"Merge options: left_on={self.left_on}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMergeError\u001b[0m: No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False"
     ]
    }
   ],
   "source": [
    "# Changing state names to abbreviations\n",
    "travel_df = travel_df.replace({'State': us_state_to_abbrev})\n",
    "cs_travel_df = cs_travel_df.replace({'State': us_state_to_abbrev})\n",
    "\n",
    "# Merging HPI and travel time dataframes\n",
    "travel_hpi = pd.merge(pd.merge(travel_df, cs_travel_df, on=['State', 'Year'], how='left'), hpi_yearly, on=['State', 'Year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPI Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Traveled to Work Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
